{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilize the dataset that is provided to make a NBA predicition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import python package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Init some parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_elo = 1600\n",
    "team_elos = {}\n",
    "team_stats = {}\n",
    "X = []\n",
    "y = []\n",
    "folder = 'data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define some helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate Elo score\n",
    "def calc_elo(win_team, lose_team):\n",
    "    winner_rank = get_elo(win_team)\n",
    "    loser_rank = get_elo(lose_team)\n",
    "\n",
    "    rank_diff = winner_rank - loser_rank\n",
    "    exp = (rank_diff * -1) / 400\n",
    "    odds = 1 / (1 + math.pow(10, exp))\n",
    "    if winner_rank < 2100:\n",
    "        k = 32\n",
    "    elif 2100 <= winner_rank < 2400:\n",
    "        k = 24\n",
    "    else:\n",
    "        k = 16\n",
    "    new_winner_rank = round(winner_rank + (k * (1 - odds)))\n",
    "    new_rank_diff = new_winner_rank - winner_rank\n",
    "    new_loser_rank = loser_rank - new_rank_diff\n",
    "\n",
    "    return new_winner_rank, new_loser_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv file and build information matrix\n",
    "def initialize_data(Mstat, Ostat, Tstat):\n",
    "    new_Mstat = Mstat.drop(['Rk', 'Arena'], axis=1)\n",
    "    new_Ostat = Ostat.drop(['Rk', 'G', 'MP'], axis=1)\n",
    "    new_Tstat = Tstat.drop(['Rk', 'G', 'MP'], axis=1)\n",
    "\n",
    "    team_stats1 = pd.merge(new_Mstat, new_Ostat, how='left', on='Team')\n",
    "    team_stats1 = pd.merge(team_stats1, new_Tstat, how='left', on='Team')\n",
    "\n",
    "    # print(team_stats1.info())\n",
    "    return team_stats1.set_index('Team', inplace=False, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_elo(team):\n",
    "    try:\n",
    "        return team_elos[team]\n",
    "    except:\n",
    "        # if not, init elo score as base_elo\n",
    "        team_elos[team] = base_elo\n",
    "        return team_elos[team]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataSet(all_data):\n",
    "    # print(\"Building data set..\")\n",
    "    for index, row in all_data.iterrows():\n",
    "        WLoc = ''\n",
    "        if float(row['PTS']) > float(row['PTS.1']):\n",
    "            Wteam = row['Visitor/Neutral']\n",
    "            Lteam = row['Home/Neutral']\n",
    "            WLoc = 'V'\n",
    "        else:\n",
    "            Wteam = row['Home/Neutral']\n",
    "            Lteam = row['Visitor/Neutral']\n",
    "            WLoc = 'H'\n",
    "\n",
    "        team1_elo = get_elo(Wteam)\n",
    "        team2_elo = get_elo(Lteam)\n",
    "\n",
    "        if WLoc == 'H':\n",
    "            team1_elo += 100\n",
    "        else:\n",
    "            team2_elo += 100\n",
    "\n",
    "        team1_features = [team1_elo]\n",
    "        team2_features = [team2_elo]\n",
    "\n",
    "        for key, value in team_stats.loc[Wteam].iteritems():\n",
    "            team1_features.append(value)\n",
    "        for key, value in team_stats.loc[Lteam].iteritems():\n",
    "            team2_features.append(value)\n",
    "\n",
    "        if random.random() > 0.5:\n",
    "            X.append(team1_features + team2_features)\n",
    "            y.append(0)\n",
    "        else:\n",
    "            X.append(team2_features + team1_features)\n",
    "            y.append(1)\n",
    "\n",
    "        new_winner_rank, new_loser_rank = calc_elo(Wteam, Lteam)\n",
    "        team_elos[Wteam] = new_winner_rank\n",
    "        team_elos[Lteam] = new_loser_rank\n",
    "\n",
    "    return np.nan_to_num(X), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load features' files. In this sample, information of 2018-19 season is loaded. If info of other season should be loaded, just modify `18-19` to the season you want, such as `15-16`, `16-17` or `17-18`. But .csv file should be storaged in `folder`(./data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mstat = pd.read_csv(folder + '/18-19Miscellaneous_Stat.csv')\n",
    "Ostat = pd.read_csv(folder + '/18-19Opponent_Per_Game_Stat.csv')\n",
    "Tstat = pd.read_csv(folder + '/18-19Team_Per_Game_Stat.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "re-format features to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_stats = initialize_data(Mstat, Ostat, Tstat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load match infos as label. In this case, trainning set and test set of match result is collected from `Year_2018_2019.csv`. Files,`Year_2016_2017.csv` and `Year_2017_2018.csv`, are open to those code by shift code of `result_data = pd.read_csv(folder + '/Year_2018_2019.csv')` to:\n",
    "\n",
    "**result_data = pd.read_csv(folder + '/Year_2016_2017.csv')** or \n",
    "\n",
    "**result_data = pd.read_csv(folder + '/Year_2017_2018.csv')**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_data = pd.read_csv(folder + '/Year_2018_2019.csv')\n",
    "X, y = build_dataSet(result_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data sets should be shuffled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "per = np.random.permutation(len(y))\n",
    "X = X[per, :]\n",
    "y = y[per]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data sets to training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample of trainning set:1049,sample of test set:263\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "print('sample of trainning set:{},sample of test set:{}'.format(len(y_train), len(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build and train LogisticRegression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score of Logistic Regression model in test set is 0.6312 (score of training set:0.6949)\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(penalty='l2', tol=0.00001, C=0.5, solver='liblinear')\n",
    "lr.fit(X_train, y_train)\n",
    "score_lr = lr.score(X_test, y_test)\n",
    "score_lr_train = lr.score(X_train, y_train)\n",
    "print('score of Logistic Regression model in test set is {:.4f} (score of training set:{:.4f})'.format(score_lr,score_lr_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build and train GaussianNB model. \n",
    "more setting:https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score of Naive Bayes (Gaussian) model in test set is 0.6236 (score of training set:0.6663)\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB(var_smoothing=1e-09)\n",
    "gnb.fit(X_train, y_train)\n",
    "score_gnb = gnb.score(X_test, y_test)\n",
    "score_gnb_train = gnb.score(X_train, y_train)\n",
    "print('score of Naive Bayes (Gaussian) model in test set is {:.4f} (score of training set:{:.4f})'.format(score_gnb,score_gnb_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build and train Random Forest model.\n",
    "more setting:https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score of Random Forest model in test set is 0.5665 (score of training set:0.9800)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "score_rf = rf.score(X_test, y_test)\n",
    "score_rf_train = rf.score(X_train, y_train)\n",
    "print('score of Random Forest model in test set is {:.4f} (score of training set:{:.4f})'.format(score_rf,score_rf_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build and train Decision Tree model.\n",
    "more setting: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score of Decision Tree model in test set is 0.5741 (score of training set:1.0000)\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "score_dt = dt.score(X_test, y_test)\n",
    "score_dt_train = dt.score(X_train, y_train)\n",
    "print('score of Decision Tree model in test set is {:.4f} (score of training set:{:.4f})'.format(score_dt,score_dt_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build and train XGBoost model. \n",
    "more setting: https://dask-ml.readthedocs.io/en/stable/modules/generated/dask_ml.xgboost.XGBClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score of XGBoost model in test set is 0.6350 (score of training set:0.8008)\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(learning_rate=0.01, max_depth=5)\n",
    "xgb.fit(X_train, y_train)\n",
    "score_xgb = xgb.score(X_test, y_test)\n",
    "score_xgb_train = xgb.score(X_train, y_train)\n",
    "print('score of XGBoost model in test set is {:.4f} (score of training set:{:.4f})'.format(score_xgb,score_xgb_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
